import os
import json
import time
import pandas as pd
import logging
import openai
from quiz_generator import QuizGenerator
from dotenv import load_dotenv, find_dotenv
from hcx_tuning import CreateTaskExecutor


# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(find_dotenv())

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# prompt.json ë¡œë“œ
with open(
    f"{os.getenv('FastAPI_DIR')}/services/text_quiz/prompt.json", "r", encoding="utf-8"
) as f:
    prompt_data = json.load(f)

# ìš”ì²­ ì œí•œ ì„¤ì •
REQUEST_LIMIT = 10  # 1ë¶„ë‹¹ ìµœëŒ€ ìš”ì²­ ìˆ˜
SLEEP_TIME = 30  # 30ì´ˆ ëŒ€ê¸°
BATCH_SIZE = 50  # 50ê°œì”© ì €ì¥ í›„ ë‹¤ìŒ ì‘ì—… ì§„í–‰
MAX_RETRIES = 5  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
RETRY_DELAY = 10  # ì¬ì‹œë„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)


def generate_hyperclova_dataset():
    api_keys = {
        "openai": os.getenv("OPENAI_API_KEY"),
        "google": os.getenv("GOOGLE_API_KEY"),
        "naver": os.getenv("NAVER_API_KEY"),
    }

    print(api_keys)

    # ë°ì´í„° ì¤€ë¹„
    csv_path = f"{os.getenv('FastAPI_DIR')}/services/text_quiz/data/text.csv"
    context_data = pd.read_csv(csv_path)
    context_data = context_data[159:]

    quiz_gen = QuizGenerator(
        api_keys, "gemini-2.0-flash-thinking-exp-01-21", context_data
    )

    output_file = (
        f"{os.getenv('FastAPI_DIR')}/services/text_quiz/data/tuning_quiz_dataset.jsonl"
    )

    request_count = 0

    with open(output_file, "w", encoding="utf-8") as f:
        for idx in range(len(context_data)):
            text_id = int(context_data.iloc[idx]["text_id"])
            title = context_data.iloc[idx]["title"]
            category = context_data.iloc[idx]["category"]
            content = context_data.iloc[idx]["content"]

            for level in range(1, 6):  # ë‚œì´ë„ 1~5
                level_prompt_key = f"level_{level}_prompt"
                if level_prompt_key in prompt_data:
                    prompt_with_level = f"{prompt_data['quiz_prompt']}\n{prompt_data[level_prompt_key]}\n\nì œëª©: {title}\nì¹´í…Œê³ ë¦¬: {category}\në³¸ë¬¸: {content}"
                else:
                    logger.error(f"âŒ {level_prompt_key}ê°€ prompt.jsonì— ì—†ìŒ")
                    continue

                retries = 0
                while retries < MAX_RETRIES:
                    try:
                        # ì±—ë´‡ì„ í˜¸ì¶œí•˜ì—¬ í€´ì¦ˆ ìƒì„±
                        _, generated_quiz = quiz_gen.generate_quiz(
                            prompt_with_level, idx
                        )

                        # JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥í•  ë°ì´í„° ìƒì„±
                        json_data = {
                            "C_ID": text_id,
                            "T_ID": level - 1,
                            "Text": prompt_with_level,
                            "Completion": generated_quiz.strip(),
                        }

                        # JSONL íŒŒì¼ì— í•œ ì¤„ì”© ì €ì¥
                        f.write(json.dumps(json_data, ensure_ascii=False) + "\n")

                        request_count += 1
                        logger.info(
                            f"âœ… ë°ì´í„° ìƒ˜í”Œ (text_id={text_id}, level={level}) ì €ì¥ ì™„ë£Œ"
                        )

                        time.sleep(8)  # ê° ìš”ì²­ë§ˆë‹¤ 8ì´ˆ ëŒ€ê¸°

                        # ìš”ì²­ ì œí•œ ì´ˆê³¼ ì‹œ ëŒ€ê¸°
                        if request_count >= REQUEST_LIMIT:
                            logger.info(f"â³ {SLEEP_TIME}ì´ˆ ë™ì•ˆ ëŒ€ê¸° ì¤‘...")
                            time.sleep(SLEEP_TIME)
                            request_count = 0  # ìš”ì²­ ê°œìˆ˜ ì´ˆê¸°í™”

                        break  # ì •ìƒ ì‹¤í–‰ë˜ë©´ ë°˜ë³µë¬¸ íƒˆì¶œ

                    except openai.error.RateLimitError as e:
                        retry_after = int(e.headers.get("Retry-After", RETRY_DELAY))
                        logger.warning(
                            f"âš ï¸ API ìš”ì²­ ì œí•œ ì´ˆê³¼! {retry_after}ì´ˆ í›„ ì¬ì‹œë„..."
                        )
                        time.sleep(retry_after)
                        retries += 1

                    except openai.error.OpenAIError as e:
                        logger.error(f"ğŸš¨ OpenAI API ì—ëŸ¬ ë°œìƒ: {e}")
                        time.sleep(RETRY_DELAY)
                        retries += 1

                # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ë¥¼ ì´ˆê³¼í•˜ë©´ ì—ëŸ¬ ë¡œê·¸ ì¶œë ¥ í›„ ì§„í–‰
                if retries >= MAX_RETRIES:
                    logger.error(
                        f"âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼! text_id={text_id}, level={level} ìŠ¤í‚µ"
                    )

            # 50ê°œ ì €ì¥ í›„ ë‹¤ìŒ ì‘ì—… ì§„í–‰
            if (idx + 1) % BATCH_SIZE == 0:
                logger.info(f"ğŸš€ 50ê°œ ì €ì¥ ì™„ë£Œ! ë‹¤ìŒ ì‘ì—… ì§„í–‰ ì¤‘...")

    logger.info(
        f"ğŸ¯ í€´ì¦ˆ ë°ì´í„°ì…‹ì´ {output_file} íŒŒì¼ì— JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
    )


def tune_model():
    task_executor = CreateTaskExecutor()

    # íŠœë‹ íŒŒë¼ë¯¸í„° ì„¤ì •
    task_name = "quiz_tuning_task"
    model = "HCX-003"  # ì‚¬ìš©í•  ëª¨ë¸ (ë³€ê²½ ê°€ëŠ¥)
    train_epochs = "8"
    learning_rate = "1e-4"
    dataset_file_path = "tuning_quiz_dataset.jsonl"  # JSONL ë°ì´í„°ì…‹ ê²½ë¡œ

    logger.info(
        f"ğŸ” íŠœë‹ ì‹œì‘: {task_name}, ëª¨ë¸: {model}, Epochs: {train_epochs}, LR: {learning_rate}"
    )

    # íŠœë‹ ìš”ì²­ ì‹¤í–‰
    tuning_result = task_executor.execute(
        task_name, model, train_epochs, learning_rate, dataset_file_path
    )

    # íŠœë‹ ê²°ê³¼ ì¶œë ¥
    logger.info(f"ğŸš€ íŠœë‹ ê²°ê³¼: {tuning_result}")

    print(tuning_result)


if __name__ == "__main__":
    while True:
        try:
            # 1. í€´ì¦ˆ ë°ì´í„° ìƒì„±
            generate_hyperclova_dataset()
            break  # ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ë©´ ì¢…ë£Œ
        except Exception as e:
            logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ ë°œìƒ: {e}, 30ì´ˆ í›„ ì¬ì‹œì‘")
            time.sleep(30)  # 30ì´ˆ ëŒ€ê¸° í›„ ë‹¤ì‹œ ì‹¤í–‰

    # 2. ë°ì´í„° ìƒì„± ì™„ë£Œ í›„, íŠœë‹ ì‹¤í–‰
    tune_model()
