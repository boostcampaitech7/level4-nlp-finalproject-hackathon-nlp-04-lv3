import os
from dotenv import load_dotenv
import requests
from bs4 import BeautifulSoup
import pandas as pd
from tqdm import tqdm

load_dotenv()


class Dictionary:

    def __init__(self, api_key):
        self.api_key = api_key

    def meaning(self, vocab):
        url = f"https://opendict.korean.go.kr/api/search?key={self.api_key}&q={vocab}&req_type=json"
        response = requests.get(url)
        data = response.json()
        if "item" not in data["channel"]:
            return None

        item = data["channel"]["item"][0]
        return {
            "vocab": vocab,
            "dict_mean": item.get("sense")[0]["definition"],
            "hanja": item.get("sense")[0]["origin"],
            "hanja_mean": self.extract_hanja(item.get("sense")[0]["link"]),
        }

    def extract_hanja(self, link):
        headers = {"User-Agent": "Mozilla/5.0"}  # User-Agent ì¶”ê°€
        response = requests.get(link, headers=headers)

        if response.status_code != 200:
            print(f"âš  ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
            return []

        soup = BeautifulSoup(response.text, "html.parser")
        hanja_list = []

        # í•œìì™€ ì²« ë²ˆì§¸ ëœ»ìŒ ì¶”ì¶œ
        for dl in soup.select(".hanja dl"):
            hanja_char_elem = dl.select_one(".hanja_font")
            first_meaning_elem = dl.select_one("dd:not(.chi_boosu)")

            if hanja_char_elem and first_meaning_elem:
                hanja_char = hanja_char_elem.text.strip()
                first_meaning = first_meaning_elem.text.strip()
                hanja_list.append((hanja_char, first_meaning))

        return hanja_list


def generate_initial_vocabs(api_key):
    df = pd.read_csv("hf://datasets/binjang/NIKL-korean-english-dictionary/2024_01.csv")
    # 1. ê³ ê¸‰ ë‹¨ì–´ë§Œ ì„ íƒ
    df = df[df["Vocabulary Level"] == "ê³ ê¸‰"]
    # 2. ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬, ë¶€ì‚¬ ë‹¨ì–´ë§Œ ì„ íƒ
    df = df[df["Part of Speech"].isin({"ëª…ì‚¬", "ë™ì‚¬", "í˜•ìš©ì‚¬", "ë¶€ì‚¬"})]
    # 3. ë‹¨ì–´ ê¸¸ì´ê°€ 2 ì´ìƒì¸ ë‹¨ì–´ë§Œ ì„ íƒ
    df = df[df["Form"].astype(str).str.len().gt(1)].reset_index(drop=True)

    dictionary = Dictionary(api_key)
    meaning_list = list()
    for index, row in tqdm(df.iterrows(), total=len(df)):
        meaning = dictionary.meaning(row["Form"])
        # 4. í•œìê°€ ì—†ìœ¼ë©´ ì œì™¸
        if len(meaning["hanja"]) != 0:
            meaning_list.append(meaning)
        if index == 100:
            break

    meaning_df = pd.DataFrame(meaning_list)
    # CSV ì €ì¥ (íŠœí”Œ ë¦¬ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ìœ ì§€)
    csv_filename = "korean_vocab_meaning.csv"
    meaning_df.to_csv(csv_filename, index=False, encoding="utf-8-sig")

    print(f"âœ… CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ! ğŸ“ {csv_filename}")


if __name__ == "__main__":
    api_key = os.getenv("OPENDICT_API_KEY")

    # 1. ë‹¨ì–´ì˜ ì •ì˜, í•œì, í•œì ëœ»ìŒ ê²€ìƒ‰í•˜ê¸°
    vocab = "ì¡´ê²½í•˜ë‹¤"
    dictionary = Dictionary(api_key)
    print(dictionary.meaning(vocab))

    # 2. NIKL-korean-english-dictionary ë°ì´í„°ì…‹ì— ìˆëŠ” ê³ ê¸‰ ë‹¨ì–´ì˜ ì •ì˜, í•œì, í•œì ëœ»ìŒ íŒŒì¼ì— ì €ì¥í•˜ê¸°
    generate_initial_vocabs(api_key)
