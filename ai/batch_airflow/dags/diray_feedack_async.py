import os
import re
import json
import asyncio
import aiohttp
import asyncpg
import logging
from datetime import datetime, timedelta
from airflow import DAG
from airflow.providers.postgres.operators.postgres import PostgresOperator
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.operators.python import PythonOperator
from dotenv import load_dotenv, find_dotenv
from pendulum import timezone


load_dotenv(find_dotenv())
logger = logging.getLogger(__name__)


kst = timezone("Asia/Seoul")
SCHEMA = os.getenv("SCHEMA").upper()
with open(f"{os.getenv('AIRFLOW_DIR')}/prompt.json", "r", encoding="utf-8") as f:
    prompt = json.load(f)


class CompletionExecutor:
    def __init__(self, model_name):
        if "HCX" in model_name:
            self._host = f"https://clovastudio.stream.ntruss.com/testapp/v1/chat-completions/{model_name}"
        else:
            self._host = f"https://clovastudio.stream.ntruss.com/testapp/v2/tasks/{model_name}/chat-completions"
        self._api_key = os.getenv("NAVER_API_KEY")

        self.hyper_parameter = {
            "topP": 0.3,
            "topK": 0,
            "maxTokens": 4096,
            "temperature": 0.5,
            "repeatPenalty": 5.0,
            "stopBefore": [],
            "includeAiFilters": True,
            "seed": 0,
        }

        self.system_prompt = prompt["feedback_prompt"]

    async def execute(self, session, diary):
        headers = {
            "Authorization": f"Bearer {self._api_key}",
            "Content-Type": "application/json; charset=utf-8",
        }

        user_prompt = f"**ì¼ê¸°**:  \n{diary}"
        messages = {
            "messages": [
                {
                    "role": "system",
                    "content": self.system_prompt,
                },
                {"role": "user", "content": user_prompt},
            ]
        }
        request_data = {**self.hyper_parameter, **messages}
        logger.info(f"request body: {request_data}")

        async with session.post(
            self._host, headers=headers, json=request_data
        ) as response:
            response_body = await response.json()
            return response_body["result"]["message"]["content"]


def check_jailbreaking(feedback):
    jailbreaking_pattern = (
        r"íƒˆì˜¥ ê°ì§€|ê²½ê³  ë©”ì‹œì§€|"
        r"ì œ ì—­í• ì€ í•™ìƒì˜ ì¼ê¸°ë¥¼ í”¼ë“œë°± í•´ì£¼ëŠ” ê²ƒì´ì—ìš”|"
        r"ì¼ê¸° í”¼ë“œë°±ì´ ì•„ë‹Œ ë‹¤ë¥¸ ìš”ì²­ì—ëŠ” ë„ì™€ë“œë¦¬ê¸° ì–´ë ¤ì›Œìš”|"
        r"ë‹¤ìŒì— ì¼ê¸°ë¥¼ ìž‘ì„±í•´ì„œ ì œì¶œí•´ ì£¼ì‹œë©´, ê¼¼ê¼¼í•˜ê²Œ ì½ê³  ì •ì„±ê» í”¼ë“œë°± í•´ ë“œë¦´ê²Œìš”"
    )
    return bool(re.search(jailbreaking_pattern, feedback))


def parse_feedback_review(diary, feedback):
    patterns = {
        "original_sentence": r"\d+\.\s*\*\*ê¸°ì¡´ ë¬¸ìž¥\*\*:\s*(.*?)\*\*ì´ìœ  ë° ê°œì„ ì \*\*",
        "feedback": r"\*\*ì´ìœ  ë° ê°œì„ ì \*\*:\s*(.*?)\*\*ìˆ˜ì • ë¬¸ìž¥\*\*",
        "updated_sentence": r"\*\*ìˆ˜ì • ë¬¸ìž¥\*\*:\s*(.*?)(?=\d+\.\s*\*\*ê¸°ì¡´ ë¬¸ìž¥\*\*|\*\*ì´í‰\*\*)",
        "review": r"\*\*ì´í‰\*\*:(.*)",
    }

    # 1. ì¼ê¸° í”¼ë“œë°±ê³¼ ë¦¬ë·° íŒŒì‹±í•˜ê¸°
    data = dict()
    for key, pattern in patterns.items():
        matches = re.findall(pattern, feedback, re.DOTALL)  # íŒ¨í„´ì— ë§žëŠ” ë¬¸ìžì—´ ì°¾ê¸°
        data[key] = [
            match.strip().strip('"') for match in matches
        ]  # ì–‘ë ê³µë°± ë° ë”°ì˜´í‘œ ì œê±°

    # 2. í˜•ì‹ì— ë§žê²Œ ë³€í™˜ (start_idx, end_idx, feedback, updated_sentence)
    feedbacks = []
    for idx, original_sentence in enumerate(data["original_sentence"]):
        matches = re.search(re.escape(original_sentence), diary)
        if matches:
            feedbacks.append(
                [
                    matches.start(),
                    matches.end(),
                    data["feedback"][idx],
                    data["updated_sentence"][idx],
                ]
            )
        else:
            feedbacks.append(
                [-1, -1, data["feedback"][idx], data["updated_sentence"][idx]]
            )

    # 3. feedbacks JSONìœ¼ë¡œ ì €ìž¥í•˜ê¸° ìœ„í•´ ì§ë ¬í™”
    feedbacks = json.dumps(feedbacks, ensure_ascii=False)
    review = data["review"][0] if data["review"] else ""
    return feedbacks, review


async def generate_save_feedback(api, session, conn, diary_id, text):
    """ê° ì¼ê¸°ë§ˆë‹¤ í”¼ë“œë°±ì„ ìƒì„±í•˜ê³  ì¦‰ì‹œ DBì— ì €ìž¥í•˜ëŠ” í•¨ìˆ˜"""

    # 1. (ë¹„ë™ê¸°) HCXë¡œ ì¼ê¸° í”¼ë“œë°± ìƒì„±
    feedback = await api.execute(session, text)  # í”¼ë“œë°± ìƒì„±
    logger.info(f"Generated Feedback for Diary {diary_id}: {feedback}")

    # 2. (ë™ê¸°) ì¼ê¸° í”¼ë“œë°±ê³¼ ë¦¬ë·° íŒŒì‹±í•˜ê¸°
    # 2.1. íƒˆì˜¥ ì—¬ë¶€ í™•ì¸
    if check_jailbreaking(feedback):
        feedbacks, review = None, None
        status = 3
        logger.warning(f"jailbreaking: {text}")
    else:
        feedbacks, review = parse_feedback_review(text, feedback)
        status = 2
        if isinstance(feedbacks, (list, dict)):
            feedbacks = json.dumps(feedbacks, ensure_ascii=False)
        logger.info(f"feedbacks: {feedbacks}")
        logger.info(f"review: {review}")

    # 3. (ë¹„ë™ê¸°) ì¼ê¸° í”¼ë“œë°±ê³¼ ë¦¬ë·° DB ì €ìž¥í•˜ê¸°
    query = f"UPDATE {SCHEMA}.DIARIES SET FEEDBACK = $1, REVIEW = $2, STATUS = $3 WHERE DIARY_ID = $4"
    await conn.execute(query, feedbacks, review, status, diary_id)

    logger.info(f"âœ… Diary {diary_id} ì—…ë°ì´íŠ¸ ì™„ë£Œ.")


async def generate_save_feedbacks(api, t1):
    """ë¹„ë™ê¸° API ìš”ì²­ ë° ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸"""
    diaries = t1.xcom_pull(task_ids="fetch_yesterday_diary")

    # 1. Airflowì˜ PostgresHookì„ í†µí•´ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì •ë³´ë¥¼ ê°€ì ¸ì˜´
    pg_hook = PostgresHook(postgres_conn_id="my_postgres_conn")
    # 2. asyncpgë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë™ê¸°ì ìœ¼ë¡œ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²°
    conn = await asyncpg.connect(dsn=pg_hook.get_uri().split("?")[0])

    async with aiohttp.ClientSession() as session:
        # 3. ì¼ê¸° í”¼ë“œë°± ìƒì„±í•˜ëŠ” íƒœìŠ¤í¬ ìƒì„± ë° ì´ë²¤íŠ¸ ë£¨í”„ì— ì‹¤í–‰ ì˜ˆì•½
        tasks = [
            asyncio.create_task(
                generate_save_feedback(api, session, conn, diary[0], diary[1])
            )
            for diary in diaries
        ]
        # 4. ëª¨ë“  íƒœìŠ¤í¬ê°€ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        await asyncio.gather(*tasks)

    # 5. ë¹„ë™ê¸°ì ìœ¼ë¡œ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì— ì—°ê²° í•´ì œ
    await conn.close()
    logger.info("ðŸŽ¯ ëª¨ë“  í”¼ë“œë°± ìƒì„± ë° ì €ìž¥ ì™„ë£Œ.")


def trigger_feedback_generation(api, **kwargs):
    asyncio.run(generate_save_feedbacks(api, kwargs["ti"]))


default_args = {
    "owner": "airflow",
    "retries": 1,
    "retry_delay": timedelta(seconds=5),
    "timezone": kst,
}

with DAG(
    dag_id="diary_feedback_async",
    default_args=default_args,
    start_date=datetime(2025, 1, 25, tzinfo=kst),
    schedule_interval="0 1 * * *",
    catchup=True,
    tags=["diary_feedback"],
) as dag:
    completion_executor = CompletionExecutor(model_name="lmh7w4qy")

    # 1. ì–´ì œ ì œì¶œí•œ ì¼ê¸° ê°€ì ¸ì˜¤ê¸°
    get_yesterday_diaries_task = PostgresOperator(
        task_id="fetch_yesterday_diary",
        postgres_conn_id="my_postgres_conn",
        sql="""
            SELECT diary_id, text
            FROM {{ params.schema }}.DIARIES
            WHERE created_at::date = '{{ macros.ds_add(ds, 1) }}'::date AND status = 1
        """,  # macros.ds_add(ds, -1) -> macros.ds_add(ds, 1)ë¡œ ìˆ˜ì • (ì‹œìŠ¤í…œ ì˜¤ë¥˜ì¸ì§€ ëª°ë¼ë„ ì´ëž˜ì•¼ ì–´ì œ ì¼ê¸°ë¥¼ ìˆ˜í–‰í•¨)
        params={"schema": SCHEMA},
        do_xcom_push=True,
    )

    # 2. ì¼ê¸° í”¼ë“œë°± ìƒì„±í•˜ê³  ì €ìž¥í•˜ê¸°
    generate_save_diary_feedback_task = PythonOperator(
        task_id="generate_save_diary_feedback",
        python_callable=trigger_feedback_generation,
        op_kwargs={"api": completion_executor},
    )

    # 3. ì¸ë±ìŠ¤ ìž¬ì •ë ¬
    sort_diary_task = PostgresOperator(
        task_id="sort_diary",
        postgres_conn_id="my_postgres_conn",
        sql="""
            CLUSTER {{ params.schema }}.DIARIES USING idx_user_created_at;
        """,
        params={"schema": SCHEMA},
    )

    get_yesterday_diaries_task >> generate_save_diary_feedback_task >> sort_diary_task
